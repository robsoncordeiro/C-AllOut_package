import random
from sklearn.utils import shuffle
import numpy as np
import matplotlib.pyplot as plt

# a function for finding a feasible list of collective cluster sizes
def collective_size_gen(total):
    collective_sizes = []

    while total > 15:
        n = random.randint(5, 15)
        collective_sizes.append(n)
        total -= n
    collective_sizes.append(total)

    return collective_sizes

# roughly 0.5% of the dataset size defines the total number of outliers
LOCAL_OUTLIERS_NUMBER = 16
GLOBAL_OUTLIERS_NUMBER = 16
COLLECTIVE_OUTLIERS_NUMBER = 16

COLLECTIVE_OUTLIERS_SIZE_POSSIBILITIES = collective_size_gen(COLLECTIVE_OUTLIERS_NUMBER)
COLLECTIVE_OUTLIERS_GROUPS = len(COLLECTIVE_OUTLIERS_SIZE_POSSIBILITIES)

meta_data = np.loadtxt("Waveform_var_synthOutlier_nin3343_nout3343.csv", delimiter=",", dtype=str, skiprows=1)
num_components = meta_data.shape[0]

# get all means from Gaussians
means = np.array(meta_data[:, 1:8].transpose())
means = means.astype(np.float)

# get all variances from Gaussians
variance = meta_data[:, -2]
variance = variance.astype(np.float)
min_variance = np.min(variance)
max_variance = np.max(variance)

# load file with points generated by Realistic Generator and get the useful parts
data = np.loadtxt("Waveform_synthOutlier_nin3343_nout3343.csv", delimiter=",", dtype=float)
num_dimensions = data.shape[1] - 2
data_labels = data[:, -1]
data_to_filter = data[:, :num_dimensions + 1]
inlier_data = data[data[:, -1] == 0][:, :num_dimensions]
outlier_data = data[data[:, -1] == 1][:, :num_dimensions]

density_data = np.loadtxt("Waveform_predictInlierDens_synthOutlier_nin3343_nout3343.csv", delimiter=",", dtype=float, skiprows=1)
inlier_density_data = density_data[:3343]
outlier_density_data = density_data[3343:]

outlier_data = np.column_stack((outlier_data, outlier_density_data))
outlier_data_sorted = outlier_data[outlier_data[:, -1].argsort()]

# intervals for selecting local and global outliers
outlier_type_index = int((len(outlier_data_sorted) * (1 - 0.683)) / 3)
local_outliers_start_index = outlier_type_index * 1
local_outliers_end_index = outlier_type_index * 2
global_outliers_end_index = outlier_type_index

local_outliers = outlier_data_sorted[local_outliers_start_index:local_outliers_end_index, :-1]
global_outliers = outlier_data_sorted[:global_outliers_end_index, :-1]

# subsample all potential local outliers and find the ones too close to each other
local_outliers = local_outliers[-1000:]
local_outliers_to_remove = []
for count, elem in enumerate(local_outliers):
    for count2, elem2 in enumerate(local_outliers):
        if count != count2 and count2 not in local_outliers_to_remove and count not in local_outliers_to_remove:
            # check if current local outlier is close to any other local outlier
            if np.linalg.norm(np.array(elem) - np.array(elem2)) < np.sqrt(max_variance) * 0.15:
                local_outliers_to_remove.append(count)
                break

# remove local outliers too close to each other
local_outliers = np.array([x for count, x in enumerate(local_outliers) if count not in local_outliers_to_remove])
local_outliers = local_outliers[-LOCAL_OUTLIERS_NUMBER:]

print("Final number of local outliers: " + str(len(local_outliers)))

# subsample all potential global outliers and find the ones too close to each other
global_outliers = global_outliers[:1000]
global_outliers_to_remove = []
for count, elem in enumerate(global_outliers):
    for count2, elem2 in enumerate(global_outliers):
        if count != count2 and count2 not in global_outliers_to_remove and count not in global_outliers_to_remove:
            # check if current global outlier is close to any other global outlier
            if np.linalg.norm(np.array(elem) - np.array(elem2)) < np.sqrt(max_variance) * 0.5:
                global_outliers_to_remove.append(count)
                break

# remove global outliers too close to each other
global_outliers = np.array([x for count, x in enumerate(global_outliers) if count not in global_outliers_to_remove])
global_outliers = global_outliers[:GLOBAL_OUTLIERS_NUMBER + COLLECTIVE_OUTLIERS_GROUPS]

# shuffle global outliers to randomly select some of them to be used as collective cluster centers
global_outliers = shuffle(global_outliers)
collective_outlier_centers = [x for x in global_outliers[-COLLECTIVE_OUTLIERS_GROUPS:, :num_dimensions]]
global_outliers = global_outliers[:GLOBAL_OUTLIERS_NUMBER]
print("Final number of global outliers: " + str(len(global_outliers)))

# generater collective outliers surrounding collective cluster centers
collective_outliers_stack = []
for count, center in enumerate(collective_outlier_centers):
    collective_cov_matrix = np.zeros((len(center), len(center)), float)
    adaptive_collective_std = random.uniform(np.sqrt(min_variance) * 0.0001, np.sqrt(min_variance) * 0.0002)
    np.fill_diagonal(collective_cov_matrix, adaptive_collective_std)

    collective_outliers_in_cluster = COLLECTIVE_OUTLIERS_SIZE_POSSIBILITIES[count]
    print("Number of collective outliers in cluster " + str(count) + ": " + str(collective_outliers_in_cluster))
    collective_outliers = np.random.multivariate_normal(center, collective_cov_matrix, collective_outliers_in_cluster)
    collective_outliers_stack.append(collective_outliers)
collective_outliers_stack = np.vstack(collective_outliers_stack)
print("Final number of collective outliers: " + str(len(collective_outliers_stack)))

# all steps below are related to labeling the selected outliers
local_outliers = local_outliers[:, :num_dimensions]
global_outliers = global_outliers[:, :num_dimensions]
local_outliers = local_outliers[:, :num_dimensions]

inlier_labels = [0] * len(inlier_data) 
local_labels = [1] * len(local_outliers)
global_labels = [2] * len(global_outliers)
collective_labels = [3] * len(collective_outliers_stack)

outlier_labels = [1] * (len(local_outliers) + len(global_outliers) + len(collective_outliers_stack))
labels = np.vstack((np.array(inlier_labels).reshape(-1, 1), np.array(outlier_labels).reshape(-1, 1)))
labels_by_type = np.vstack((np.array(inlier_labels).reshape(-1, 1), np.array(local_labels).reshape(-1, 1), np.array(global_labels).reshape(-1, 1), np.array(collective_labels).reshape(-1, 1)))
all_data_stack = np.vstack((inlier_data, local_outliers, global_outliers, collective_outliers_stack))

np.savetxt("Waveform_realistic.txt", all_data_stack, fmt='%.9f', delimiter=';')
np.savetxt("y_Waveform_realistic.txt", labels, fmt='%.9f', delimiter=';')
np.savetxt("ytype_Waveform_realistic.txt", labels_by_type, fmt='%.9f', delimiter=';')

outlier_labels = [1] * len(local_outliers)
labels = np.vstack((np.array(inlier_labels).reshape(-1, 1), np.array(outlier_labels).reshape(-1, 1)))
labels_by_type = np.vstack((np.array(inlier_labels).reshape(-1, 1), np.array(local_labels).reshape(-1, 1)))
all_data_stack = np.vstack((inlier_data, local_outliers))
np.savetxt("Waveform_realistic_local.txt", all_data_stack, fmt='%.9f', delimiter=';')
np.savetxt("y_Waveform_realistic_local.txt", labels, fmt='%.9f', delimiter=';')
np.savetxt("ytype_Waveform_realistic_local.txt", labels_by_type, fmt='%.9f', delimiter=';')

outlier_labels = [1] * len(global_outliers)
labels = np.vstack((np.array(inlier_labels).reshape(-1, 1), np.array(outlier_labels).reshape(-1, 1)))
labels_by_type = np.vstack((np.array(inlier_labels).reshape(-1, 1), np.array(global_labels).reshape(-1, 1)))
all_data_stack = np.vstack((inlier_data, global_outliers))
np.savetxt("Waveform_realistic_global.txt", all_data_stack, fmt='%.9f', delimiter=';')
np.savetxt("y_Waveform_realistic_global.txt", labels, fmt='%.9f', delimiter=';')
np.savetxt("ytype_Waveform_realistic_global.txt", labels_by_type, fmt='%.9f', delimiter=';')

outlier_labels = [1] * len(collective_outliers_stack)
labels = np.vstack((np.array(inlier_labels).reshape(-1, 1), np.array(outlier_labels).reshape(-1, 1)))
labels_by_type = np.vstack((np.array(inlier_labels).reshape(-1, 1), np.array(collective_labels).reshape(-1, 1)))
all_data_stack = np.vstack((inlier_data, collective_outliers_stack))
np.savetxt("Waveform_realistic_collective.txt", all_data_stack, fmt='%.9f', delimiter=';')
np.savetxt("y_Waveform_realistic_collective.txt", labels, fmt='%.9f', delimiter=';')
np.savetxt("ytype_Waveform_realistic_collective.txt", labels_by_type, fmt='%.9f', delimiter=';')